{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 1 #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Программа работает с файлом \"hw_3_twitter.json\", расположенным в одной папке с программой. Файл считывается и построчно превращается в словари Python.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import collections\n",
    "import string\n",
    "from string import punctuation\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "twitter = []\n",
    "with open(\"hw_3_twitter.json\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        twitter.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пункты 1-7 ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 1 ###\n",
    "Поскольку каждая строка - это один твит, выясним, сколько твитов в наборе, посчитав длину получившегося в предыдущем действии списка (twitter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество твитов в наборе составляет 2556\n"
     ]
    }
   ],
   "source": [
    "twit_amount = len(twitter)\n",
    "print(\"Количество твитов в наборе составляет\", twit_amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 2 ###\n",
    "Найдем процент удаленных твитов, посчитав количество твитов с пометкой \"delete\" и разделив его на общее количество твитов (значение округлено до сотых)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процент удаленных твитов составляет 14.16 %\n"
     ]
    }
   ],
   "source": [
    "del_twit_amount = 0\n",
    "for tweet in twitter:\n",
    "    if \"delete\" in tweet:\n",
    "        del_twit_amount += 1\n",
    "if twit_amount:  # мы точно не знаем, что общее число твитов больше 0, поэтому защитимся от деления на 0\n",
    "    del_percentage = round((del_twit_amount / twit_amount) * 100, 2)\n",
    "    print(\"Процент удаленных твитов составляет\", del_percentage, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 3 ###\n",
    "Выясним, какие языки наиболее популярны. Для этого сначала составим список из всех языков, встретившихся в твитах (lang_list), при этом исключив из рассмотрения удаленные твиты, т.к. они не содержат информации о языке. Далее на основе полученного списка составим частотный словарь языков (freq_lang), отсортируем словарь по значениям в обратном порядке и распечатаем первые 10 пар \"ключ: значение\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-10 самых популярных языков:\n",
      "en - 719 твитов\n",
      "ja - 438 твитов\n",
      "es - 173 твитов\n",
      "ko - 149 твитов\n",
      "th - 123 твитов\n",
      "ar - 119 твитов\n",
      "und - 117 твитов\n",
      "in - 71 твитов\n",
      "pt - 69 твитов\n",
      "fr - 35 твитов\n"
     ]
    }
   ],
   "source": [
    "lang_list = []\n",
    "for tweet in twitter:\n",
    "    if \"delete\" not in tweet:\n",
    "        lang = tweet[\"lang\"]\n",
    "        lang_list.append(lang)\n",
    "\n",
    "freq_lang = collections.Counter(lang_list)\n",
    "\n",
    "print(\"Топ-10 самых популярных языков:\")\n",
    "for number, key in enumerate(sorted(freq_lang, key=freq_lang.get, reverse=True)):\n",
    "    if number < 10:\n",
    "        print(key, \"-\", freq_lang[key], \"твитов\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 4 ###\n",
    "Узнаем, есть ли твиты от одного и того же пользователя (**включая удаленные твиты**). Будем по одному добавлять id пользователей в список user_ids (для не-удаленных твитов id содержится внутри tweet[\"user\"][\"id\"], для удаленных - в поле tweet[\"delete\"][\"status\"][\"user_id\"]). Таким образом, в списке user_ids каждое имя пользователя будет встречаться столько раз, сколько твитов написал этот пользователь.\n",
    "Далее создадим частотный словарь с именами пользователей, добавим тех, кто написал более одного твита, в список repeated_users и выведем длину этого списка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пользователей, написавших больше одного твита, составляет 66\n"
     ]
    }
   ],
   "source": [
    "user_ids = []\n",
    "for tweet in twitter:\n",
    "    if \"user\" in tweet:\n",
    "        user_id = tweet[\"user\"][\"id\"]\n",
    "    if \"delete\" in tweet:\n",
    "        user_id = tweet[\"delete\"][\"status\"][\"user_id\"]\n",
    "    user_ids.append(user_id)\n",
    "\n",
    "users = collections.Counter(user_ids)\n",
    "repeated_users = []\n",
    "for user in users:\n",
    "    if users[user] > 1:\n",
    "        repeated_users.append(user)\n",
    "print(\"Количество пользователей, написавших больше одного твита, составляет\", len(repeated_users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 4 (вариант 2) ###\n",
    "На всякий случай - вариант **без учета удаленных твитов**. Алгоритм работы кода в целом тот же, что и в первом случае."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пользователей, написавших больше одного твита, составляет 25\n"
     ]
    }
   ],
   "source": [
    "user_ids = []\n",
    "for tweet in twitter:\n",
    "    if \"delete\" not in tweet:\n",
    "        user_id = tweet[\"user\"][\"id\"]\n",
    "        user_ids.append(user_id)\n",
    "\n",
    "users = collections.Counter(user_ids)\n",
    "repeated_users = []\n",
    "for user in users:\n",
    "    if users[user] > 1:\n",
    "        repeated_users.append(user)\n",
    "print(\"Количество пользователей, написавших больше одного твита, составляет\", len(repeated_users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 5 ###\n",
    "Выясним, какие хэштеги наиболее популярны (будем работать только с не-удаленными твитами, т.к. у удаленных тегов нет). Соберем все хэштеги, хранящиеся внутри [\"entities\"][\"hashtags\"], в общий список hashtags, и удалим из этого списка пустые элементы с помощью filter. Поскольку каждым элементом hashtags является не отдельный хэштег, а список хэштегов (+ дополнительная информация о них) из какого-либо твита, с помощью вложенного цикла вытащим собственно теги из [\"entities\"][\"hashtags\"][\"text\"] и сложим их в список cleared_hashtags. Далее создадим частотный словарь хэштегов, отсортируем его по убыванию значений и запишем первые 20 ключей в список top20_list, который затем \"красиво\" выведем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-20 хэштегов:\n",
      "BTS - 17 употреблений\n",
      "방탄소년단 - 13 употреблений\n",
      "AMAs - 11 употреблений\n",
      "人気投票ガチャ - 8 употреблений\n",
      "태형 - 7 употреблений\n",
      "뷔 - 6 употреблений\n",
      "BTSinChicago - 5 употреблений\n",
      "BTSLoveYourselfTour - 5 употреблений\n",
      "오늘의방탄 - 5 употреблений\n",
      "PledgeForSwachhBharat - 5 употреблений\n",
      "MPN - 5 употреблений\n",
      "PCAs - 4 употреблений\n",
      "V - 4 употреблений\n",
      "시카고1회차공연 - 4 употреблений\n",
      "เป๊กผลิตโชค - 4 употреблений\n",
      "JIMIN - 4 употреблений\n",
      "running - 3 употреблений\n",
      "NCT - 3 употреблений\n",
      "지민 - 3 употреблений\n",
      "WajahmuPlastik - 3 употреблений\n"
     ]
    }
   ],
   "source": [
    "hashtags = []\n",
    "for tweet in twitter:\n",
    "    if \"delete\" not in tweet:\n",
    "        hashtag_list = tweet[\"entities\"][\"hashtags\"]\n",
    "        hashtags.append(hashtag_list)\n",
    "\n",
    "hashtags = list(filter(None, hashtags))\n",
    "\n",
    "cleared_hashtags = []\n",
    "for element in hashtags:\n",
    "    for tags in element:\n",
    "        tag = tags[\"text\"]\n",
    "        cleared_hashtags.append(tag)\n",
    "\n",
    "print(\"Топ-20 хэштегов:\")\n",
    "top_hashtags = collections.Counter(cleared_hashtags)\n",
    "for number, hashtag in enumerate(sorted(top_hashtags, key=top_hashtags.get, reverse=True)):\n",
    "    if number < 20:\n",
    "        print(hashtag, \"-\", top_hashtags[hashtag], \"употреблений\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 6 ###\n",
    "Составим частотный словарь всех слов в оригинальных твитах на английском языке. Сначала соберем все тексты подходящих (англоязычных, не-ретвитнутых и не-удаленных) твитов в список en_tweet_texts. Чтобы получить эти тексты, нужно использовать:\n",
    "\n",
    "1) поле \"extended_tweet\"[\"full_text\"], если оно есть (а есть оно не во всех твитах);\n",
    "\n",
    "2) поле \"text\" в остальных случаях.\n",
    "\n",
    "Далее пройдемся по каждому тексту в цикле и с помощью split разделим тексты на отдельные слова/числа/ссылки/эмодзи и т.д., после чего получившиеся единицы запишем в общий список full_tokens.\n",
    "Теперь обработаем получившиеся \"слова\". Приведем их к нижнему регистру с помощью lower, избавимся от эмодзи с помощью encode и decode, проверим, что слово не является ссылкой, хэштегом или обращением к пользователю (не начинается на http, # или @), после чего удалим знаки препинания, убедимся, что слово действительно является словом (а не, например, числом) и добавим его в общий список words. На основе полученного списка создадим частотный словарь freq_dict, отсортируем его по значениям в обратном порядке и выведем первые 10 пар \"ключ: значение\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-20 наиболее частотных слов:\n",
      "the - 134 вхождений\n",
      "to - 96 вхождений\n",
      "a - 74 вхождений\n",
      "and - 69 вхождений\n",
      "i - 68 вхождений\n",
      "you - 54 вхождений\n",
      "of - 51 вхождений\n",
      "is - 50 вхождений\n",
      "it - 49 вхождений\n",
      "for - 44 вхождений\n",
      "in - 43 вхождений\n",
      "that - 35 вхождений\n",
      "me - 31 вхождений\n",
      "on - 30 вхождений\n",
      "my - 27 вхождений\n",
      "be - 25 вхождений\n",
      "its - 24 вхождений\n",
      "this - 22 вхождений\n",
      "are - 22 вхождений\n",
      "your - 21 вхождений\n"
     ]
    }
   ],
   "source": [
    "en_tweet_texts = []\n",
    "for tweet in twitter:\n",
    "    if \"delete\" not in tweet and \"retweeted_status\" not in tweet and \"quoted_status\" not in tweet and tweet[\"lang\"] == \"en\":\n",
    "        if \"extended_tweet\" in tweet:\n",
    "            en_tweet_texts.append(tweet[\"extended_tweet\"][\"full_text\"])\n",
    "        else:\n",
    "            en_tweet_texts.append(tweet[\"text\"])\n",
    "\n",
    "full_tokens = []\n",
    "for tweet in en_tweet_texts:\n",
    "    tokens = tweet.split()\n",
    "    full_tokens.extend(tokens)   \n",
    "\n",
    "words = []\n",
    "for token in full_tokens:\n",
    "    word = ((token.lower()).encode('ascii', 'ignore')).decode('ascii')\n",
    "    if not (word.startswith(\"http\") or word.startswith(\"#\") or word.startswith(\"@\")):\n",
    "        word = word.translate(word.maketrans(\"\", \"\", string.punctuation))\n",
    "        if word.isalpha():\n",
    "            words.append(word)\n",
    "\n",
    "print(\"Топ-20 наиболее частотных слов:\")\n",
    "freq_dict = collections.Counter(words)\n",
    "for number, word in enumerate(sorted(freq_dict, key=freq_dict.get, reverse=True)):\n",
    "    if number < 20:\n",
    "        print(word, \"-\", freq_dict[word], \"вхождений\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 7 ###\n",
    "Выясним, у кого из пользователей наибольшее число подписчиков. Будем работать только с не-удаленными твитами, поскольку в удаленных эта информация отсутствует.\n",
    "Из каждого твита вытащим имя пользователя, хранящееся в поле tweet[\"user\"][\"screen_name\"], и количество подписчиков из поля tweet[\"user\"][\"followers_count\"]. Затем запишем полученную информацию в словарь followers_leaders в формате \"имя пользователя: количество подписчиков\", каждый раз проверяя, что данных этого пользователя еще нет в словаре.\n",
    "Отсортировав полученный словарь по значениям в обратном порядке, распечатаем первые 10 пар \"ключ: значение\", добавляя к данным подписи для \"красоты\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-10 пользователей с наибольшим количеством подписчиков:\n",
      "1 место - пользователь FIL0S0FIA: 2521403 подписчиков\n",
      "2 место - пользователь FitnessMagazine: 1491309 подписчиков\n",
      "3 место - пользователь malaysiakini: 1206759 подписчиков\n",
      "4 место - пользователь NYTScience: 1137374 подписчиков\n",
      "5 место - пользователь GramaticaReal: 625463 подписчиков\n",
      "6 место - пользователь tgrthabertv: 392472 подписчиков\n",
      "7 место - пользователь TheSunFootball: 383698 подписчиков\n",
      "8 место - пользователь Melbourne: 374222 подписчиков\n",
      "9 место - пользователь Roznama_Express: 318189 подписчиков\n",
      "10 место - пользователь burger_boogie: 311319 подписчиков\n"
     ]
    }
   ],
   "source": [
    "followers_leaders = {}\n",
    "for tweet in twitter:\n",
    "    if \"delete\" not in tweet:\n",
    "        username = tweet[\"user\"][\"screen_name\"]\n",
    "        follower_count = tweet[\"user\"][\"followers_count\"]\n",
    "        if username not in followers_leaders:\n",
    "            followers_leaders[username] = follower_count\n",
    "        \n",
    "print(\"Топ-10 пользователей с наибольшим количеством подписчиков:\")\n",
    "for number, key in enumerate(sorted(followers_leaders, key=followers_leaders.get, reverse=True)):\n",
    "    if number < 10:\n",
    "        string = str(number + 1) + \" место - пользователь \" + key + \": \" + str(followers_leaders[key]) + \" подписчиков\"\n",
    "        print(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пункт 8 ##\n",
    "Выясним, каковы самые распространенные приложения для Твиттера. Вновь будем работать только с не-удаленными твитами.\n",
    "Ситуация различается для оригинальных твитов и ретвитов: у оригинального твита только один источник, а у ретвита два - источник самого твита и источник ретвита. **Учтем все случаи**.\n",
    "Для оригинальных твитов извлечем источник из поля \"source\" при помощи регулярного выражения и запишем его в список sources. Для ретвитов найдем источник оригинального твита (поле \"retweeted_status\"[\"source\"]) и источник ретвита (поле \"source\") и запишем их в тот же список.\n",
    "Создадим частотный словарь источников твитов (sources_freq), отсортируем его по значениям в обратном порядке и распечатаем первые 10 элементов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-10 источников твита:\n",
      "Twitter for iPhone - 1281 твитов\n",
      "Twitter for Android - 964 твитов\n",
      "Twitter Web Client - 303 твитов\n",
      "twittbot.net - 123 твитов\n",
      "Twitter Lite - 65 твитов\n",
      "TweetDeck - 41 твитов\n",
      "Twitter for iPad - 38 твитов\n",
      "IFTTT - 20 твитов\n",
      "Facebook - 19 твитов\n",
      "Hootsuite Inc. - 18 твитов\n"
     ]
    }
   ],
   "source": [
    "sources = []\n",
    "for tweet in twitter:\n",
    "    if \"delete\" not in tweet:\n",
    "        if \"retweeted_status\" not in tweet:\n",
    "            source = (re.search('<a href=\"(.*?)>(.*?)</a>', tweet[\"source\"])).group(2)\n",
    "        else:\n",
    "            source = (re.search('<a href=\"(.*?)>(.*?)</a>', tweet[\"retweeted_status\"][\"source\"])).group(2)\n",
    "            retweet_source = (re.search('<a href=\"(.*?)>(.*?)</a>', tweet[\"source\"])).group(2)\n",
    "            sources.append(retweet_source)\n",
    "        sources.append(source)\n",
    "\n",
    "sources_freq = collections.Counter(sources)\n",
    "print(\"Топ-10 источников твита:\")\n",
    "for number, source in enumerate(sorted(sources_freq, key=sources_freq.get, reverse=True)):\n",
    "    if number < 10:\n",
    "        print(source, \"-\", sources_freq[source], \"твитов\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пункт 8 (вариант 2) ##\n",
    "На всякий случай - вариант, учитывающий только источники твитов \"верхнего слоя\" (т.е. не учитывающий источники ретвитнутых твитов, а учитывающий только источник самого ретвита)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-10 источников твита:\n",
      "Twitter for iPhone - 800 твитов\n",
      "Twitter for Android - 695 твитов\n",
      "Twitter Web Client - 140 твитов\n",
      "twittbot.net - 122 твитов\n",
      "Twitter Lite - 51 твитов\n",
      "Twitter for iPad - 28 твитов\n",
      "TweetDeck - 23 твитов\n",
      "Facebook - 17 твитов\n",
      "IFTTT - 14 твитов\n",
      "تطبيق قرآني - 10 твитов\n"
     ]
    }
   ],
   "source": [
    "sources = []\n",
    "for tweet in twitter:\n",
    "    if \"delete\" not in tweet:\n",
    "        source = (re.search('<a href=\"(.*?)>(.*?)</a>', tweet[\"source\"])).group(2)\n",
    "        sources.append(source)\n",
    "\n",
    "sources_freq = collections.Counter(sources)\n",
    "print(\"Топ-10 источников твита:\")\n",
    "for number, source in enumerate(sorted(sources_freq, key=sources_freq.get, reverse=True)):\n",
    "    if number < 10:\n",
    "        print(source, \"-\", sources_freq[source], \"твитов\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
